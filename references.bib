
@article{schaal_is_1999,
	title = {Is imitation learning the route to humanoid robots?},
	volume = {3},
	issn = {13646613},
	doi = {10.1016/S1364-6613(99)01327-3},
	language = {en},
	number = {6},
	urldate = {2023-07-24},
	journal = {Trends in Cognitive Sciences},
	author = {Schaal, Stefan},
	month = jun,
	year = {1999},
	pages = {233--242},
}

@article{argall_survey_2009,
	title = {A survey of robot learning from demonstration},
	volume = {57},
	issn = {09218890},
	doi = {10.1016/j.robot.2008.10.024},
	language = {en},
	number = {5},
	urldate = {2023-07-24},
	journal = {Robotics and Autonomous Systems},
	author = {Argall, Brenna D. and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
	month = may,
	year = {2009},
	pages = {469--483},
}

@article{ravichandar_recent_2020,
	title = {Recent {Advances} in {Robot} {Learning} from {Demonstration}},
	volume = {3},
	issn = {2573-5144, 2573-5144},
	doi = {10.1146/annurev-control-100819-063206},
	abstract = {In the context of robotics and automation, learning from demonstration (LfD) is the paradigm in which robots acquire new skills by learning to imitate an expert. The choice of LfD over other robot learning methods is compelling when ideal behavior can be neither easily scripted (as is done in traditional robot programming) nor easily defined as an optimization problem, but can be demonstrated. While there have been multiple surveys of this field in the past, there is a need for a new one given the considerable growth in the number of publications in recent years. This review aims to provide an overview of the collection of machine-learning methods used to enable a robot to learn from and imitate a teacher. We focus on recent advancements in the field and present an updated taxonomy and characterization of existing methods. We also discuss mature and emerging application areas for LfD and highlight the significant challenges that remain to be overcome both in theory and in practice.},
	language = {en},
	number = {1},
	urldate = {2023-07-24},
	journal = {Annual Review of Control, Robotics, and Autonomous Systems},
	author = {Ravichandar, Harish and Polydoros, Athanasios S. and Chernova, Sonia and Billard, Aude},
	month = may,
	year = {2020},
	pages = {297--330},
}

@inproceedings{pastor_learning_2009,
	title = {Learning and generalization of motor skills by learning from demonstration},
	doi = {10.1109/ROBOT.2009.5152385},
	abstract = {We provide a general approach for learning robotic motor skills from human demonstration. To represent an observed movement, a non-linear differential equation is learned such that it reproduces this movement. Based on this representation, we build a library of movements by labeling each recorded movement according to task and context (e.g., grasping, placing, and releasing). Our differential equation is formulated such that generalization can be achieved simply by adapting a start and a goal parameter in the equation to the desired position values of a movement. For object manipulation, we present how our framework extends to the control of gripper orientation and finger position. The feasibility of our approach is demonstrated in simulation as well as on the Sarcos dextrous robot arm. The robot learned a pick-and-place operation and a water-serving task and could generalize these tasks to novel situations.},
	booktitle = {2009 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Pastor, Peter and Hoffmann, Heiko and Asfour, Tamim and Schaal, Stefan},
	month = may,
	year = {2009},
	note = {ISSN: 1050-4729},
	keywords = {Robots, Differential equations, Libraries, Humans, Grippers, Fingers, Robustness, Robotics and automation, Labeling, Anthropomorphism},
	pages = {763--768},
}

@article{calinon_learning_2007,
	title = {On {Learning}, {Representing}, and {Generalizing} a {Task} in a {Humanoid} {Robot}},
	volume = {37},
	issn = {1083-4419},
	doi = {10.1109/TSMCB.2006.886952},
	number = {2},
	urldate = {2023-07-24},
	journal = {IEEE Transactions on Systems, Man and Cybernetics, Part B (Cybernetics)},
	author = {Calinon, Sylvain and Guenter, Florent and Billard, Aude},
	month = apr,
	year = {2007},
	pages = {286--298},
}

@article{darvish_teleoperation_2023,
	title = {Teleoperation of {Humanoid} {Robots}: {A} {Survey}},
	volume = {39},
	issn = {1552-3098, 1941-0468},
	shorttitle = {Teleoperation of {Humanoid} {Robots}},
	doi = {10.1109/TRO.2023.3236952},
	number = {3},
	urldate = {2023-07-24},
	journal = {IEEE Transactions on Robotics},
	author = {Darvish, Kourosh and Penco, Luigi and Ramos, Joao and Cisneros, Rafael and Pratt, Jerry and Yoshida, Eiichi and Ivaldi, Serena and Pucci, Daniele},
	month = jun,
	year = {2023},
	pages = {1706--1727},
}

@incollection{sammut_learning_1992,
	address = {San Francisco (CA)},
	title = {Learning to {Fly}},
	isbn = {9781558602472},
	abstract = {This paper describes experiments in applying inductive learning to the task of acquiring a complex motor skill by observing human subjects. A flight simulation program has been modified to log the actions of a human subject as he or she flies an aircraft. The log file is used to create the input to an induction program. The output from the induction program is tested by running the simulator in autopilot mode where the autopilot code is derived from the decision tree formed by induction. The autopilot must fly the plane according to a strictly defined flight plan.},
	language = {en},
	urldate = {2023-07-24},
	booktitle = {Machine {Learning} {Proceedings} 1992},
	publisher = {Morgan Kaufmann},
	author = {Sammut, Claude and Hurst, Scott and Kedzier, Dana and Michie, Donald},
	editor = {Sleeman, Derek and Edwards, Peter},
	month = jan,
	year = {1992},
	doi = {10.1016/B978-1-55860-247-2.50055-3},
	pages = {385--393},
}

@misc{wu_prim-lafd:_2022,
	title = {Prim-{LAfD}: {A} {Framework} to {Learn} and {Adapt} {Primitive}-{Based} {Skills} from {Demonstrations} for {Insertion} {Tasks}},
	shorttitle = {Prim-{LAfD}},
	doi = {10.48550/arXiv.2212.00955},
	abstract = {Learning generalizable insertion skills in a data-efficient manner has long been a challenge in the robot learning community. While the current state-of-the-art methods with reinforcement learning (RL) show promising performance in acquiring manipulation skills, the algorithms are data-hungry and hard to generalize. To overcome the issues, in this paper we present Prim-LAfD, a simple yet effective framework to learn and adapt primitive-based insertion skills from demonstrations. Prim-LAfD utilizes black-box function optimization to learn and adapt the primitive parameters leveraging prior experiences. Human demonstrations are modeled as dense rewards guiding parameter learning. We validate the effectiveness of the proposed method on eight peg-hole and connector-socket insertion tasks. The experimental results show that our proposed framework takes less than one hour to acquire the insertion skills and as few as fifteen minutes to adapt to an unseen insertion task on a physical robot.},
	urldate = {2023-07-24},
	publisher = {arXiv},
	author = {Wu, Zheng and Lian, Wenzhao and Wang, Changhao and Li, Mengxi and Schaal, Stefan and Tomizuka, Masayoshi},
	month = dec,
	year = {2022},
	note = {arXiv:2212.00955 [cs]},
	keywords = {Computer Science - Robotics},
}

@article{ramirez-amaro_understanding_2015,
	title = {Understanding the intention of human activities through semantic perception: observation, understanding and execution on a humanoid robot},
	volume = {29},
	issn = {0169-1864, 1568-5535},
	shorttitle = {Understanding the intention of human activities through semantic perception},
	doi = {10.1080/01691864.2014.1003096},
	language = {en},
	number = {5},
	urldate = {2023-07-24},
	journal = {Advanced Robotics},
	author = {Ramirez-Amaro, Karinne and Beetz, Michael and Cheng, Gordon},
	month = mar,
	year = {2015},
	pages = {345--362},
}

@inproceedings{ando_master-slave_2020,
	address = {Honolulu, HI, USA},
	title = {Master-{Slave} {Bipedal} {Walking} and {Semi}-{Automatic} {Standing} {Up} of {Humanoid} {Robots}},
	isbn = {9781728166674},
	urldate = {2023-07-24},
	booktitle = {2020 {IEEE}/{SICE} {International} {Symposium} on {System} {Integration} ({SII})},
	publisher = {IEEE},
	author = {Ando, Tomoya and Watari, Tomofumi and Kikuuwe, Ryo},
	month = jan,
	year = {2020},
	pages = {360--365},
}

@article{fang_skill_2019,
	title = {Skill learning for human-robot interaction using wearable device},
	volume = {24},
	issn = {1007-0214},
	doi = {10.26599/TST.2018.9010096},
	number = {6},
	urldate = {2023-07-24},
	journal = {Tsinghua Science and Technology},
	author = {Fang, Bin and Wei, Xiang and Sun, Fuchun and Huang, Haiming and Yu, Yuanlong and Liu, Huaping},
	month = dec,
	year = {2019},
	pages = {654--662},
}

@inproceedings{vecerik_practical_2019,
	address = {Montreal, QC, Canada},
	title = {A {Practical} {Approach} to {Insertion} with {Variable} {Socket} {Position} {Using} {Deep} {Reinforcement} {Learning}},
	isbn = {9781538660270},
	doi = {10.1109/ICRA.2019.8794074},
	urldate = {2023-07-24},
	booktitle = {2019 {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Vecerik, Mel and Sushkov, Oleg and Barker, David and Rothorl, Thomas and Hester, Todd and Scholz, Jon},
	month = may,
	year = {2019},
	pages = {754--760},
}

@inproceedings{rouot_inverse_2017,
	address = {Melbourne, Australia},
	title = {On inverse optimal control via polynomial optimization},
	isbn = {9781509028733},
	doi = {10.1109/CDC.2017.8263745},
	urldate = {2023-07-24},
	booktitle = {2017 {IEEE} 56th {Annual} {Conference} on {Decision} and {Control} ({CDC})},
	publisher = {IEEE},
	author = {Rouot, Jeremy and Lasserre, Jean-Bernard},
	month = dec,
	year = {2017},
	pages = {721--726},
}

@INPROCEEDINGS{advice_operator,
  author={Argall, Brenna D. and Browning, Brett and Veloso, Manuela},
  booktitle={2008 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Learning robot motion control with demonstration and advice-operators}, 
  year={2008},
  volume={},
  number={},
  pages={399-404},
  doi={10.1109/IROS.2008.4651020}}

@misc{yu_one-shot_2018,
	title = {One-{Shot} {Imitation} from {Observing} {Humans} via {Domain}-{Adaptive} {Meta}-{Learning}},
	doi = {10.48550/arXiv.1802.01557},
	abstract = {Humans and animals are capable of learning a new behavior by observing others perform the skill just once. We consider the problem of allowing a robot to do the same -- learning from a raw video pixels of a human, even when there is substantial domain shift in the perspective, environment, and embodiment between the robot and the observed human. Prior approaches to this problem have hand-specified how human and robot actions correspond and often relied on explicit human pose detection systems. In this work, we present an approach for one-shot learning from a video of a human by using human and robot demonstration data from a variety of previous tasks to build up prior knowledge through meta-learning. Then, combining this prior knowledge and only a single video demonstration from a human, the robot can perform the task that the human demonstrated. We show experiments on both a PR2 arm and a Sawyer arm, demonstrating that after meta-learning, the robot can learn to place, push, and pick-and-place new objects using just one video of a human performing the manipulation.},
	urldate = {2023-07-24},
	publisher = {arXiv},
	author = {Yu, Tianhe and Finn, Chelsea and Xie, Annie and Dasari, Sudeep and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
	month = feb,
	year = {2018},
	note = {arXiv:1802.01557 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
}

@inproceedings{rana_towards_2017,
	title = {Towards {Robust} {Skill} {Generalization}: {Unifying} {Learning} from {Demonstration} and {Motion} {Planning}},
	shorttitle = {Towards {Robust} {Skill} {Generalization}},
	abstract = {In this paper, we present Combined Learning from demonstration And Motion Planning (CLAMP) as an efficient approach to skill learning and generalizable skill reproduction. CLAMP combines the strengths of Learning from Demonstration (LfD) and motion planning into a unifying framework. We carry out probabilistic inference to find trajectories which are optimal with respect to a given skill and also feasible in different scenarios. We use factor graph optimization to speed up inference. To encode optimality, we provide a new probabilistic skill model based on a stochastic dynamical system. This skill model requires minimal parameter tuning to learn, is suitable to encode skill constraints, and allows efficient inference. Preliminary experimental results showing skill generalization over initial robot state and unforeseen obstacles are presented.},
	language = {en},
	urldate = {2023-07-24},
	booktitle = {Proceedings of the 1st {Annual} {Conference} on {Robot} {Learning}},
	publisher = {PMLR},
	author = {Rana, Muhammad Asif and Mukadam, Mustafa and Ahmadzadeh, Seyed Reza and Chernova, Sonia and Boots, Byron},
	month = oct,
	year = {2017},
	pages = {109--118},
}

@inproceedings{zhang_deep_2018,
	address = {Brisbane, QLD},
	title = {Deep {Imitation} {Learning} for {Complex} {Manipulation} {Tasks} from {Virtual} {Reality} {Teleoperation}},
	isbn = {9781538630815},
	doi = {10.1109/ICRA.2018.8461249},
	urldate = {2023-07-24},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Zhang, Tianhao and McCarthy, Zoe and Jow, Owen and Lee, Dennis and Chen, Xi and Goldberg, Ken and Abbeel, Pieter},
	month = may,
	year = {2018},
	pages = {5628--5635},
}

@article{zhao_variational_2023,
	title = {Variational {Diversity} {Maximization} for {Hierarchical} {Skill} {Discovery}},
	volume = {55},
	issn = {1370-4621, 1573-773X},
	doi = {10.1007/s11063-022-10912-8},
	language = {en},
	number = {1},
	urldate = {2023-07-24},
	journal = {Neural Processing Letters},
	author = {Zhao, Yingnan and Liu, Peng and Zhao, Wei and Tang, Xianglong},
	month = feb,
	year = {2023},
	pages = {839--855},
}

@misc{chuck2023grangercausal,
      title={Granger-Causal Hierarchical Skill Discovery}, 
      author={Caleb Chuck and Kevin Black and Aditya Arjun and Yuke Zhu and Scott Niekum},
      year={2023},
      eprint={2306.09509},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{ijspeert_movement_2002,
	address = {Washington, DC, USA},
	title = {Movement imitation with nonlinear dynamical systems in humanoid robots},
	volume = {2},
	isbn = {9780780372726},
	doi = {10.1109/ROBOT.2002.1014739},
	urldate = {2023-07-24},
	booktitle = {Proceedings 2002 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({Cat}. {No}.{02CH37292})},
	publisher = {IEEE},
	author = {Ijspeert, A.J. and Nakanishi, J. and Schaal, S.},
	year = {2002},
	pages = {1398--1403},
}

@article{ijspeert_dynamical_2013,
	title = {Dynamical {Movement} {Primitives}: {Learning} {Attractor} {Models} for {Motor} {Behaviors}},
	volume = {25},
	issn = {0899-7667, 1530-888X},
	shorttitle = {Dynamical {Movement} {Primitives}},
	doi = {10.1162/NECO_a_00393},
	abstract = {Nonlinear dynamical systems have been used in many disciplines to model complex behaviors, including biological motor control, robotics, perception, economics, traffic prediction, and neuroscience. While often the unexpected emergent behavior of nonlinear systems is the focus of investigations, it is of equal importance to create goal-directed behavior (e.g., stable locomotion from a system of coupled oscillators under perceptual guidance). Modeling goal-directed behavior with nonlinear systems is, however, rather difficult due to the parameter sensitivity of these systems, their complex phase transitions in response to subtle parameter changes, and the difficulty of analyzing and predicting their long-term behavior; intuition and time-consuming parameter tuning play a major role. This letter presents and reviews dynamical movement primitives, a line of research for modeling attractor behaviors of autonomous nonlinear dynamical systems with the help of statistical learning techniques. The essence of our approach is to start with a simple dynamical system, such as a set of linear differential equations, and transform those into a weakly nonlinear system with prescribed attractor dynamics by means of a learnable autonomous forcing term. Both point attractors and limit cycle attractors of almost arbitrary complexity can be generated. We explain the design principle of our approach and evaluate its properties in several example applications in motor control and robotics.},
	language = {en},
	number = {2},
	urldate = {2023-07-24},
	journal = {Neural Computation},
	author = {Ijspeert, Auke Jan and Nakanishi, Jun and Hoffmann, Heiko and Pastor, Peter and Schaal, Stefan},
	month = feb,
	year = {2013},
	pages = {328--373},
}

@inproceedings{meier_movement_2011,
	title = {Movement segmentation using a primitive library},
	doi = {10.1109/IROS.2011.6094676},
	abstract = {Segmenting complex movements into a sequence of primitives remains a difficult problem with many applications in the robotics and vision communities. In this work, we show how the movement segmentation problem can be reduced to a sequential movement recognition problem. To this end, we reformulate the original Dynamic Movement Primitive (DMP) formulation as a linear dynamical system with control inputs. Based on this new formulation, we develop an Expectation-Maximization algorithm to estimate the duration and goal position of a partially observed trajectory. With the help of this algorithm and the assumption that a library of movement primitives is present, we present a movement segmentation framework. We illustrate the usefulness of the new DMP formulation on the two applications of online movement recognition and movement segmentation.},
	booktitle = {2011 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Meier, Franziska and Theodorou, Evangelos and Stulp, Freek and Schaal, Stefan},
	month = sep,
	year = {2011},
	note = {ISSN: 2153-0866},
	keywords = {Trajectory, Libraries, Motion segmentation, Covariance matrix, Noise, Equations},
	pages = {3407--3412},
}

@article{caccavale_kinesthetic_2019,
	title = {Kinesthetic teaching and attentional supervision of structured tasks in human–robot interaction},
	volume = {43},
	issn = {0929-5593, 1573-7527},
	doi = {10.1007/s10514-018-9706-9},
	language = {en},
	number = {6},
	urldate = {2023-07-24},
	journal = {Autonomous Robots},
	author = {Caccavale, Riccardo and Saveriano, Matteo and Finzi, Alberto and Lee, Dongheui},
	month = aug,
	year = {2019},
	pages = {1291--1307},
}

@inproceedings{saran_enhancing_2019,
	title = {Enhancing {Robot} {Learning} with {Human} {Social} {Cues}},
	doi = {10.1109/HRI.2019.8673178},
	abstract = {Imagine a learning scenario between two humans: a teacher demonstrating how to play a new musical instrument or a craftsman teaching a new skill like pottery or knitting to a novice. Even though learning a skill has a learning curve to get the nuances of the technique right, some basic social principles are followed between the teacher and the student to make the learning process eventually succeed. There are several assumptions or social priors in this communication for teaching: mutual eye contact to draw attention to instructions, following the gaze of the teacher to understand the skill, the teacher following the student's gaze during imitation to give feedback, the teacher demonstrating by pointing towards something she is going to approach or manipulate and verbal interruptions or corrections during the learning process [1], [2]. In prior research, verbal and non-verbal social cues such as eye gaze and gestures have been shown to make human-human interactions seamless and augment verbal, collaborative behavior [3], [4]. They serve as an indicator of engagement, interest and attention when people interact face-to-face with one another [5], [6].},
	booktitle = {2019 14th {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction} ({HRI})},
	author = {Saran, Akanksha and Short, Elaine Schaertl and Thomaz, Andrea and Niekum, Scott},
	month = mar,
	year = {2019},
	note = {ISSN: 2167-2148},
	keywords = {Human-robot interaction, Task analysis, Education, Visualization, Two dimensional displays, Robot learning},
	pages = {745--747},
}

@article{stulp_reinforcement_2012,
	title = {Reinforcement {Learning} {With} {Sequences} of {Motion} {Primitives} for {Robust} {Manipulation}},
	volume = {28},
	issn = {1941-0468},
	doi = {10.1109/TRO.2012.2210294},
	abstract = {Physical contact events often allow a natural decomposition of manipulation tasks into action phases and subgoals. Within the motion primitive paradigm, each action phase corresponds to a motion primitive, and the subgoals correspond to the goal parameters of these primitives. Current state-of-the-art reinforcement learning algorithms are able to efficiently and robustly optimize the parameters of motion primitives in very high-dimensional problems. These algorithms often consider only shape parameters, which determine the trajectory between the start- and end-point of the movement. In manipulation, however, it is also crucial to optimize the goal parameters, which represent the subgoals between the motion primitives. We therefore extend the policy improvement with path integrals (PI2) algorithm to simultaneously optimize shape and goal parameters. Applying simultaneous shape and goal learning to sequences of motion primitives leads to the novel algorithm PI2 Seq. We use our methods to address a fundamental challenge in manipulation: improving the robustness of everyday pick-and-place tasks.},
	number = {6},
	journal = {IEEE Transactions on Robotics},
	author = {Stulp, Freek and Theodorou, Evangelos A. and Schaal, Stefan},
	month = dec,
	year = {2012},
	keywords = {Learning systems, Adaptive systems, Learning, Manipulators, Grasping, Learning and adaptive systems, manipulation planning, reinforcement learning},
	pages = {1360--1370},
}

@inproceedings{kroemer_towards_2015,
	address = {Seattle, WA, USA},
	title = {Towards learning hierarchical skills for multi-phase manipulation tasks},
	isbn = {9781479969234},
	doi = {10.1109/ICRA.2015.7139389},
	urldate = {2023-07-24},
	booktitle = {2015 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Kroemer, Oliver and Daniel, Christian and Neumann, Gerhard and Van Hoof, Herke and Peters, Jan},
	month = may,
	year = {2015},
	pages = {1503--1510},
}

@article{calinon_learning_2010,
	title = {Learning and {Reproduction} of {Gestures} by {Imitation}},
	volume = {17},
	issn = {1558-223X},
	doi = {10.1109/MRA.2010.936947},
	abstract = {We presented and evaluated an approach based on HMM, GMR, and dynamical systems to allow robots to acquire new skills by imitation. Using HMM allowed us to get rid of the explicit time dependency that was considered in our previous work [12], by encapsulating precedence information within the statistical representation. In the context of separated learning and reproduction processes, this novel formulation was systematically evaluated with respect to our previous approach, LWR [20], LWPR [21], and DMPs [13]. We finally presented applications on different kinds of robots to highlight the flexibility of the proposed approach in three different learning by imitation scenarios.},
	number = {2},
	journal = {IEEE Robotics \& Automation Magazine},
	author = {Calinon, Sylvain and D'halluin, Florent and Sauser, Eric L. and Caldwell, Darwin G. and Billard, Aude G.},
	month = jun,
	year = {2010},
	keywords = {Hidden Markov models, Humans, Humanoid robots, Robustness, Encoding, Character generation, Feeds, Robot programming, Education, Educational robots},
	pages = {44--54},
}

@article{niekum_learning_2015,
	title = {Learning grounded finite-state representations from unstructured demonstrations},
	volume = {34},
	issn = {0278-3649, 1741-3176},
	doi = {10.1177/0278364914554471},
	abstract = {Robots exhibit flexible behavior largely in proportion to their degree of knowledge about the world. Such knowledge is often meticulously hand-coded for a narrow class of tasks, limiting the scope of possible robot competencies. Thus, the primary limiting factor of robot capabilities is often not the physical attributes of the robot, but the limited time and skill of expert programmers. One way to deal with the vast number of situations and environments that robots face outside the laboratory is to provide users with simple methods for programming robots that do not require the skill of an expert. For this reason, learning from demonstration (LfD) has become a popular alternative to traditional robot programming methods, aiming to provide a natural mechanism for quickly teaching robots. By simply showing a robot how to perform a task, users can easily demonstrate new tasks as needed, without any special knowledge about the robot. Unfortunately, LfD often yields little knowledge about the world, and thus lacks robust generalization capabilities, especially for complex, multi-step tasks. We present a series of algorithms that draw from recent advances in Bayesian non-parametric statistics and control theory to automatically detect and leverage repeated structure at multiple levels of abstraction in demonstration data. The discovery of repeated structure provides critical insights into task invariants, features of importance, high-level task structure, and appropriate skills for the task. This culminates in the discovery of a finite-state representation of the task, composed of grounded skills that are flexible and reusable, providing robust generalization and transfer in complex, multi-step robotic tasks. These algorithms are tested and evaluated using a PR2 mobile manipulator, showing success on several complex real-world tasks, such as furniture assembly.},
	language = {en},
	number = {2},
	urldate = {2023-07-24},
	journal = {The International Journal of Robotics Research},
	author = {Niekum, Scott and Osentoski, Sarah and Konidaris, George and Chitta, Sachin and Marthi, Bhaskara and Barto, Andrew G.},
	month = feb,
	year = {2015},
	pages = {131--157},
}

@misc{saveriano_dynamic_2021,
	title = {Dynamic {Movement} {Primitives} in {Robotics}: {A} {Tutorial} {Survey}},
	shorttitle = {Dynamic {Movement} {Primitives} in {Robotics}},
	doi = {10.48550/arXiv.2102.03861},
	abstract = {Biological systems, including human beings, have the innate ability to perform complex tasks in versatile and agile manner. Researchers in sensorimotor control have tried to understand and formally define this innate property. The idea, supported by several experimental findings, that biological systems are able to combine and adapt basic units of motion into complex tasks finally lead to the formulation of the motor primitives theory. In this respect, Dynamic Movement Primitives (DMPs) represent an elegant mathematical formulation of the motor primitives as stable dynamical systems, and are well suited to generate motor commands for artificial systems like robots. In the last decades, DMPs have inspired researchers in different robotic fields including imitation and reinforcement learning, optimal control,physical interaction, and human-robot co-working, resulting a considerable amount of published papers. The goal of this tutorial survey is two-fold. On one side, we present the existing DMPs formulations in rigorous mathematical terms,and discuss advantages and limitations of each approach as well as practical implementation details. In the tutorial vein, we also search for existing implementations of presented approaches and release several others. On the other side, we provide a systematic and comprehensive review of existing literature and categorize state of the art work on DMP. The paper concludes with a discussion on the limitations of DMPs and an outline of possible research directions.},
	urldate = {2023-06-25},
	publisher = {arXiv},
	author = {Saveriano, Matteo and Abu-Dakka, Fares J. and Kramberger, Aljaz and Peternel, Luka},
	month = feb,
	year = {2021},
	note = {arXiv:2102.03861 [cs]},
	keywords = {Computer Science - Robotics},
}

@INPROCEEDINGS{sensory_skill,
  author={Pastor, Peter and Kalakrishnan, Mrinal and Righetti, Ludovic and Schaal, Stefan},
  booktitle={2012 12th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2012)}, 
  title={Towards Associative Skill Memories}, 
  year={2012},
  volume={},
  number={},
  pages={309-315},
  doi={10.1109/HUMANOIDS.2012.6651537}}

@INPROCEEDINGS{sensory_seg,
  author={Su, Zhe and Kroemer, Oliver and Loeb, Gerald E. and Sukhatme, Gaurav S. and Schaal, Stefan},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Learning Manipulation Graphs from Demonstrations Using Multimodal Sensory Signals}, 
  year={2018},
  volume={},
  number={},
  pages={2758-2765},
  doi={10.1109/ICRA.2018.8461121}}

@inproceedings{singh2023mc,
  title={mc-mujoco: Simulating Articulated Robots with FSM Controllers in MuJoCo},
  author={Singh, Rohan P and Gergondet, Pierre and Kanehiro, Fumio},
  booktitle={2023 IEEE/SICE International Symposium on System Integration (SII)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@inbook{pearson,
author = {Benesty, Jacob and Chen, Jingdong and Huang, Yiteng and Cohen, Israel},
year = {2009},
month = {04},
pages = {1-4},
title = {Pearson Correlation Coefficient},
volume = {2},
isbn = {978-3-642-00295-3},
journal = {Noise Reduction in Speech Processing},
doi = {10.1007/978-3-642-00296-0_5}
}

@inproceedings{hrp4,
author = {Kajita, Shuuji and Kaneko, Kenji and Kanehiro, Fumio and Harada, Kensuke and Morisawa, Mitsuharu and Nakaoka, Shinichiro and Miura, Kanako and Fujiwara, Kiyoshi and Neo, Ee Sian and Hara, Isao},
year = {2009},
month = {01},
pages = {301-314},
title = {Cybernetic Human HRP-4C: A Humanoid Robot with Human-Like Proportions.}
}

@INPROCEEDINGS{jvrc,
  author={Okugawa, M. and Oogane, K. and Shimizu, M. and Ohtsubo, Y. and Kimura, T. and Takahashi, T. and Tadokoro, S.},
  booktitle={2015 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)}, 
  title={Proposal of inspection and rescue tasks for tunnel disasters — Task development of Japan virtual robotics challenge}, 
  year={2015},
  volume={},
  number={},
  pages={1-2},
  doi={10.1109/SSRR.2015.7443005}}

@article{clasp,
	doi = {10.1007/s10618-023-00923-x},
	year = 2023,
	month = {feb},
  	publisher = {Springer Science and Business Media {LLC}
},
    volume = {37},
    number = {3},
    pages = {1262--1300},
    author = {Arik Ermshaus and Patrick Schäfer and Ulf Leser},
    title = {{ClaSP}: parameter-free time series segmentation},
    journal = {Data Mining and Knowledge Discovery}
}

@ARTICLE{dtw,
  author={Sakoe, H. and Chiba, S.},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
  title={Dynamic programming algorithm optimization for spoken word recognition}, 
  year={1978},
  volume={26},
  number={1},
  pages={43-49},
  doi={10.1109/TASSP.1978.1163055}}
